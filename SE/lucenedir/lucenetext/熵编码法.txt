熵编码法

熵编码法是一种独立于介质的具体特征的进行无损数据压缩的方案。

一种主要类型的熵编码方式是对输入的每一个符号，创建并分配一个唯一的前缀码，然后，通过将每个固定长度的输入符号替换成相应的可变长度前缀无关（prefix-free）输出码字替换，从而达到压缩数据的目的。每个码字的长度近似与概率的负对数成比例。因此，最常见的符号使用最短的码。

根据香农的信源编码定理，一个符号的最佳码长是 −log"P"，其中 "b" 是用来输出的码的数目，"P" 是输入符号出现的概率。

霍夫曼编码和算术编码是两种最常见的熵编码技术。如果预先已知数据流的近似熵特性（尤其是对于信号压缩），可以使用简单的静态码。这些静态码，包括通用密码（如Elias gamma coding或斐波那契编码）和哥伦布编码（比如元编码或Rice编码）。

一般熵编码器与其它编码器联合使用。比如LHA首先使用LZ编码，然后将其结果进行熵编码。Zip和Bzip的最后一级编码也是熵编码。

使用长度不同的比特串对字母进行编码有一定的困难。尤其是，几乎所有几率的熵都是一个有理数。

霍夫曼编码建议了一种将位元进位成整数的演算法，但这个演算法在特定情况下无法达到最佳结果。为此有人加以改进，提供最佳整数位元数。这个演算法使用二元树来设立一个编码。这个二叉树的终端节点代表被编码的字母，根节点代表使用的位元。

除这个对每个要编码的数据产生一个特别的表格的方法外还有使用固定的编码表的方法。比如加入要编码的数据中符号出现的机率符合一定的规则的话就可以使用特别的变长编码表。这样的编码表具有一定的系数来使得它适应实际的字母出现机率。

使用整数比特的方法往往无法获得使用熵计算的比特数，因此其压缩并非一定最佳。

比如字母列由两个不同的字母组成，其中一个字母的可能性是formula_1，另一个字母的可能性是formula_2。以上算法的结果是每个字母应该用一个比特来代表，因此其结果的比特数与字母数相同。

但扩展取样位数可以稍微弥补该破绽：上例的formula_3、formula_4、formula_5、formula_6，以霍夫曼编码算法得结果为：每两个字母平均用formula_7个比特，即平均每个字母用0.84375个比特来代表，向最佳熵值踏近了一步。

最佳熵编码器应该为第一个字母使用formula_8个比特，为第二个字母使用formula_9个比特，因此整个结果是每个字母平均使用formula_10个比特。

使用算术编码可以改善这个结果，使得原信息按照熵最佳来编码。

要确定每个字母的比特数算法需要尽可能精确地知道每个字母的出现机率。模型的任务是提供这个数据。模型的预言越好压缩的结果就越好。此外模型必须在压缩和恢复时提出同样的数据。在历史上有许多不同的模型。

静态模型在压缩前对整个文字进行分析计算每个字母的机率。这个计算结果用于整个文字上。

在这个模型里机率随编码过程而不断变化。多种算法可以达到这个目的：

一般在动态模型中不使用机率，而使用每个字母出现的次数。

除上述的前向和反向模型外还有其它的动态模型计算方法。

比如在前向模型中可以不时减半出现过的字母的次数来降低一开始的字母的影响力。

对于尚未出现过的字母的处理方法也有许多不同的手段：比如假设每个字母正好出现一次，这样所有的字母均可被编码。

模型度说明模型顾及历史上多少个字母。比如模型度0说明模型顾及整个原文。模型度1说明模型顾及原文中的上一个字母并不断改变其机率。模型度可以无限高，但是对于大的原文来说模型度越高其需要的计算内存也越多。

除了使用熵编码作为压缩数字数据一种方法外，熵编码器也可以用来测量数据流和已经存在的类的数据之间的相似程度。这是通过对每类数据产生一个熵编码器/压缩器；通过将未压缩的数据提供给每个压缩机，据该压缩机产生的最佳压缩分类。具有最佳压缩率的编码器可能是用与未知数据最相似的数据训练的编码器。

